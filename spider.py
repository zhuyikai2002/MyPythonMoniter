import requests
from bs4 import BeautifulSoup

# 1. ç¡®å®šç›®æ ‡ï¼šä½ è‡ªå·±çš„åšå®¢
url = 'https://qzkj.ltd/blog'

# 2. ä¼ªè£…è‡ªå·±ï¼šå‘Šè¯‰æœåŠ¡å™¨â€œæˆ‘æ˜¯æµè§ˆå™¨â€ï¼Œä¸æ˜¯å¯ç–‘çš„è„šæœ¬
# (è™½ç„¶ä½ çˆ¬è‡ªå·±ä¸éœ€è¦è¿™æ­¥ï¼Œä½†å…»æˆå¥½ä¹ æƒ¯å¾ˆé‡è¦)
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

print(f"ğŸ•·ï¸ æ­£åœ¨æ‚„æ‚„é è¿‘ç›®æ ‡: {url} ...")

# 3. å‘èµ·æ”»å‡»ï¼šå‘é€ GET è¯·æ±‚
try:
    response = requests.get(url, headers=headers)

    # ã€é‡ç‚¹ã€‘å¼ºåˆ¶å‘Šè¯‰ Pythonï¼šè¿™ä¸ªç½‘é¡µæ˜¯ UTF-8 ç¼–ç çš„ï¼
    response.encoding = 'utf-8'

    # æ£€æŸ¥æ˜¯ä¸æ˜¯æˆåŠŸäº† (200 ä»£è¡¨æˆåŠŸï¼Œ404 ä»£è¡¨æ‰¾ä¸åˆ°)
    if response.status_code == 200:
        print("âœ… æˆåŠŸæ½œå…¥ï¼æœåŠ¡å™¨è¿”å› 200 OK")

        # 4. è§£ææˆ˜åˆ©å“ï¼šæŠŠç½‘é¡µæºä»£ç äº¤ç»™ BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')

        # 5. æå–æ•°æ®ï¼šæ‰¾åˆ° <title> æ ‡ç­¾é‡Œçš„æ–‡å­—
        # ä½ çš„åšå®¢æ ‡é¢˜åº”è¯¥è—åœ¨è¿™é‡Œ
        blog_title = soup.title.string
        print(f"\nğŸ† æŠ“å–åˆ°çš„åšå®¢æ ‡é¢˜æ˜¯ï¼š\nğŸ‘‰ {blog_title}")

        # è¿›é˜¶ï¼šè¯•ç€æŠ“å–æ‰€æœ‰æ–‡ç« çš„æ ‡é¢˜ï¼ˆHexo é»˜è®¤é€šå¸¸ç”¨ .post-title ç±»åï¼‰
        # è¿™é‡Œåªæ˜¯æ¼”ç¤ºï¼Œå¦‚æœæ²¡æŠ“åˆ°è¯´æ˜ä½ çš„ä¸»é¢˜ç±»åä¸ä¸€æ ·ï¼Œé‚£æ˜¯æ­£å¸¸çš„
        print("\nğŸ” æ­£åœ¨æœç´¢é¦–é¡µçš„æ–‡ç« åˆ—è¡¨...")
        articles = soup.find_all('a', class_='post-title-link')
        for i, article in enumerate(articles):
            print(f"{i + 1}. {article.text.strip()}")

    else:
        print(f"âŒ å“å‘€ï¼Œè¢«å‘ç°äº†ï¼ŸçŠ¶æ€ç : {response.status_code}")

except Exception as e:
    print(f"ğŸ’¥ å‘ç”Ÿé”™è¯¯: {e}")